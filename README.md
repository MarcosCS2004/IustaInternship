# üèõÔ∏è Project: Law Firms in Germany

This project automates the search and collection of information about law firms in Germany using APIs, web scraping, custom bots, and data processing. Its goal is to centralize and classify useful data from various sources such as Google, LinkedIn, and law firm-specific websites.

---

## üìÅ Project Structure

```
|
‚îú‚îÄ‚îÄ main.py
|
‚îú‚îÄ‚îÄ scripts/
‚îÇ    ‚îú‚îÄ‚îÄ bots/                                       # Bots for web navigation and scraping
|    ‚îÇ   ‚îú‚îÄ‚îÄ browsers/                               # General scrapers 
|    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linkedin_bot.py
|    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_finder_bot.py
|    ‚îÇ   ‚îú‚îÄ‚îÄ lawfirms/                               # Law firm-specific scrapers
|    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bot_scraper.py
|    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ filtered_bot.py
|    ‚îÇ   ‚îî‚îÄ‚îÄ specific_pages/                         # Step-by-step scrapers from a specific URL
|    ‚îÇ       ‚îú‚îÄ‚îÄ get_links_step1.py
|    ‚îÇ       ‚îî‚îÄ‚îÄ get_data_from_links_step2.py
|    ‚îú‚îÄ‚îÄ filters/                                    # Filtering and classification
|    ‚îÇ   ‚îú‚îÄ‚îÄ filter_links_by_words_step1.py
|    ‚îÇ   ‚îú‚îÄ‚îÄ filter_useful_links_step2.py
|    ‚îÇ   ‚îú‚îÄ‚îÄ classify_links_by_category_step3.py
|    ‚îÇ   ‚îî‚îÄ‚îÄ split_by_category_step4.py
|    ‚îú‚îÄ‚îÄ search/                                     # Initial search via API
|    ‚îÇ   ‚îî‚îÄ‚îÄ search_lawyers_api.py
|    ‚îî‚îÄ‚îÄ tools/                                      # General utility scripts
|        ‚îî‚îÄ‚îÄ put_space_after_comma.py
|
‚îú‚îÄ‚îÄ data/
|    ‚îú‚îÄ‚îÄ raw/                                        # Raw, unprocessed data
|    ‚îî‚îÄ‚îÄ processed/                                  # Cleaned/ready data
|
‚îî‚îÄ‚îÄ logs/                                           # Execution logs
    ‚îî‚îÄ‚îÄ run_log.txt

```

---

## üõ†Ô∏è Technologies Used

- **Python 3.9+**
- **Selenium** (browser automation)
- **Requests** and **BeautifulSoup** (HTML scraping)
- **SerpAPI** (Google Search API)
- **Pandas** (data processing)

---

## üöÄ Installation

1. Clone the repository:
```bash
git clone https://github.com/MarcosCS2004/IustaInternship

```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate        # Linux/macOS
venv\Scripts\activate           # Windows
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ‚öôÔ∏è How to Use

### Step 1: Search for law firms via Google API
```bash
python scripts/search/search_lawyers_api.py
```

### Step 2: Filter and classify the collected links
```bash
python scripts/filters/filter_links_by_words_step1.py
python scripts/filters/filter_useful_links_step2.py
python scripts/filters/classify_links_by_category_step3.py
python scripts/filters/split_by_category_step4.py
```

### Step 3: Clean up text (optional)
```bash
python scripts/tools/put_space_after_comma.py
```

### Step 4: Scrape data from specific pages
```bash
python scripts/bots/specific_pages/get_links_step1.py
python scripts/bots/specific_pages/get_data_from_links_step2.py
```

---

## üßæ Execution Logging (Optional)

To log progress, errors, or key events during script execution, you can use a simple logging function that writes to `logs/run_log.txt`.

### Logging function

```python
from datetime import datetime

def log_message(message):
    with open("logs/run_log.txt", "a") as f:
        f.write(f"[{datetime.now()}] {message}\n")
```

### üí° Example usage in a script

```python
log_message("Started scraping LinkedIn.")
# ... your code ...
log_message("Scraping completed. 150 profiles found.")
```

> Make sure the `logs/` directory exists, or create it with `os.makedirs("logs", exist_ok=True)` before writing to the log.

---

## Additional Requirements

- A valid Google Search API key (stored as an environment variable or directly in the script).
- (Optional) Active LinkedIn session or cookies if using LinkedIn scraping.

---

## üìÑ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT). You are free to use, modify, or distribute it as long as you retain the copyright.

---

## ‚úçÔ∏è Author

Developed by Geanina Foanta and Marcos Calvo.
